{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a753f6fe-b8c0-4dd0-a9c9-4ca1017dddef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3763d7e-32ef-457f-aaa0-53a939d70544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Azif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Azif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Azif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Azif\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eafb9dd6-0dcc-4806-9f87-8f2d9561de2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news_dataset.csv')\n",
    "df = df[['text']]  # Keep only the text column\n",
    "df.dropna(inplace=True)  # Remove null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9dc6405-3e85-4613-bae9-c1778c84cf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was wondering if anyone out there could enli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently posted an article asking what kind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nIt depends on your priorities.  A lot of peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an excellent automatic can be found in the sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Ford and his automobile.  I need information...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  I was wondering if anyone out there could enli...\n",
       "1  I recently posted an article asking what kind ...\n",
       "2  \\nIt depends on your priorities.  A lot of peo...\n",
       "3  an excellent automatic can be found in the sub...\n",
       "4  : Ford and his automobile.  I need information..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81093298-42d9-423b-87d6-59531220ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'\\d+', '', text)  # remove numbers\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))  # remove punctuation\n",
    "    tokens = word_tokenize(text)  # tokenize\n",
    "    tokens = [t for t in tokens if t not in stop_words and len(t) > 3]  # remove stopwords and short tokens\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens]  # lemmatize\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df['text'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2ddd51-5090-4e44-a112-fe677ec92614",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(df['tokens'])\n",
    "corpus = [dictionary.doc2bow(text) for text in df['tokens']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "664a93b1-9316-480a-a7b8-f14864120063",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaModel(corpus=corpus,\n",
    "                                   id2word=dictionary,\n",
    "                                   num_topics=4,\n",
    "                                   random_state=100,\n",
    "                                   update_every=1,\n",
    "                                   chunksize=100,\n",
    "                                   passes=10,\n",
    "                                   alpha='auto',\n",
    "                                   per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ff5b1e3-ec96-4afb-b886-6104f34b225d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score: 0.5066238862749219\n"
     ]
    }
   ],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=df['tokens'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_score = coherence_model_lda.get_coherence()\n",
    "print(f'Coherence Score: {coherence_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc0fb4a4-0f31-467d-b0e5-a0e61d651a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.003*\"blbh\" + 0.002*\"trinomials\" + 0.002*\"boomer\" + 0.002*\"maxaxaxaxaxaxaxaxaxaxaxaxaxaxax\" + 0.002*\"scorer\" + 0.002*\"calgary\" + 0.001*\"winnipeg\" + 0.001*\"bhcssimaxbyte\" + 0.001*\"drake\" + 0.001*\"scand\"\n",
      "Topic 2: 0.005*\"istanbul\" + 0.003*\"cable\" + 0.003*\"ankara\" + 0.003*\"bayonet\" + 0.002*\"serdar\" + 0.002*\"argic\" + 0.002*\"hojali\" + 0.002*\"negev\" + 0.002*\"azeri\" + 0.002*\"erzurum\"\n",
      "Topic 3: 0.009*\"would\" + 0.008*\"people\" + 0.006*\"dont\" + 0.005*\"government\" + 0.005*\"know\" + 0.005*\"think\" + 0.005*\"right\" + 0.005*\"time\" + 0.005*\"like\" + 0.004*\"could\"\n",
      "Topic 4: 0.015*\"encryption\" + 0.015*\"chip\" + 0.012*\"system\" + 0.010*\"information\" + 0.009*\"key\" + 0.008*\"privacy\" + 0.008*\"file\" + 0.007*\"program\" + 0.007*\"data\" + 0.007*\"message\"\n"
     ]
    }
   ],
   "source": [
    "topics = lda_model.print_topics(num_words=10)\n",
    "for i, topic in topics:\n",
    "    print(f\"Topic {i+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6145f1-b5d5-44d9-b1af-7d4061ec8ea2",
   "metadata": {},
   "source": [
    "#The coherence score obtained for the LDA model is 0.5066, which shows an okay level of topic interpetration. \n",
    "Typically coherence scores ranges from 0 to 1. What this means is that higher values suggest that the topics \n",
    "generated by the model are more semantically consistent and meaningful. Scoring above 0.5 is\n",
    "generally acceptable, especially  for text data like public articles, which can be noisy or covers a lot of themes. \n",
    "The current score suggests that the topics make some logical sense there is still room for improvement\n",
    "by cleaning the text further or experimenting with a different number of topics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
